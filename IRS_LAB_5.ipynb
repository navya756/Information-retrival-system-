{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download necessary datasets\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v33C55H8Gotn",
        "outputId": "aaf5db7f-c777-4150-a31a-1df26e5eff3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = [\"running\", \"happier\", \"flies\", \"unbelievable\", \"replaying\"]\n",
        "\n",
        "for word in words:\n",
        "    lemma = lemmatizer.lemmatize(word, pos='v')  # 'v' for verbs\n",
        "    print(f\"Word: {word} -> Lemma: {lemma}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEzrjwLUGyd5",
        "outputId": "25657137-c6db-4be8-b0e9-ce9d424dd0c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: running -> Lemma: run\n",
            "Word: happier -> Lemma: happier\n",
            "Word: flies -> Lemma: fly\n",
            "Word: unbelievable -> Lemma: unbelievable\n",
            "Word: replaying -> Lemma: replay\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "prefixes = [\"un\", \"re\", \"pre\", \"mis\", \"dis\", \"non\", \"in\", \"im\", \"ir\", \"il\"]\n",
        "suffixes = [\"ing\", \"ed\", \"s\", \"es\", \"er\", \"est\", \"ly\", \"ment\", \"ness\", \"able\"]\n",
        "\n",
        "def analyze_morphology(word):\n",
        "    root = word\n",
        "    prefix_found, suffix_found = \"\", \"\"\n",
        "\n",
        "    # Check for prefixes\n",
        "    for prefix in prefixes:\n",
        "        if word.startswith(prefix):\n",
        "            prefix_found = prefix\n",
        "            root = word[len(prefix):]\n",
        "            break\n",
        "\n",
        "    # Check for suffixes\n",
        "    for suffix in suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            suffix_found = suffix\n",
        "            root = root[:-len(suffix)]\n",
        "            break\n",
        "\n",
        "    return {\"Word\": word, \"Prefix\": prefix_found, \"Root\": root, \"Suffix\": suffix_found}\n",
        "\n",
        "words = [\"unbelievable\", \"replaying\", \"happiness\", \"disapprove\", \"running\"]\n",
        "\n",
        "for word in words:\n",
        "    print(analyze_morphology(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wnsbNeaG2jV",
        "outputId": "d90c4cdd-fa16-4e62-f87e-f9e2cab5ab5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Word': 'unbelievable', 'Prefix': 'un', 'Root': 'believ', 'Suffix': 'able'}\n",
            "{'Word': 'replaying', 'Prefix': 're', 'Root': 'play', 'Suffix': 'ing'}\n",
            "{'Word': 'happiness', 'Prefix': '', 'Root': 'happines', 'Suffix': 's'}\n",
            "{'Word': 'disapprove', 'Prefix': 'dis', 'Root': 'approve', 'Suffix': ''}\n",
            "{'Word': 'running', 'Prefix': '', 'Root': 'runn', 'Suffix': 'ing'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "word = \"replaying\"\n",
        "doc = nlp(word)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"Word: {token.text}\")\n",
        "    print(f\"Lemma: {token.lemma_}\")\n",
        "    print(f\"Morphology: {token.morph}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qO42JogG57G",
        "outputId": "5647540e-ac13-475b-f8a4-ac208deb6eac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: replaying\n",
            "Lemma: replay\n",
            "Morphology: Aspect=Prog|Tense=Pres|VerbForm=Part\n"
          ]
        }
      ]
    }
  ]
}